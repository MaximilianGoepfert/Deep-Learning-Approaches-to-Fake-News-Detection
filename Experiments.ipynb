{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, CSVLogger\n",
    "from  tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from  tensorflow.keras.preprocessing import sequence\n",
    "from  tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from  tensorflow.keras.models import Sequential\n",
    "from  tensorflow.keras.layers import Dense,Flatten,LSTM,Conv1D,GlobalMaxPool1D,Dropout,Bidirectional,GRU\n",
    "from  tensorflow.keras.layers import Embedding\n",
    "from  tensorflow.keras import optimizers\n",
    "from  tensorflow.keras.layers import Input\n",
    "from  tensorflow.keras.models import Model\n",
    "from  tensorflow.keras.utils import plot_model\n",
    "from  tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "####\n",
    "# Load datasets from previously saved pickle files\n",
    "####\n",
    "liar_df_train = pickle.load(open('/content/augmemted_train2.pkl', 'rb'))\n",
    "liar_df_val= pickle.load(open('/content/augmemted_val.pkl','rb'))\n",
    "liar_df_test= pickle.load(open('/content/augmemted_test.pkl','rb'))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "####\n",
    "# Load GloVe 100 dimension\n",
    "####\n",
    "embeddings = {}\n",
    "with open(\"/content/glove.6B.100d.txt\", encoding=\"utf8\") as file_object:\n",
    "    for line in file_object:\n",
    "        word_embed = line.split()\n",
    "        word = word_embed[0]\n",
    "        embed = np.array(word_embed[1:], dtype=\"float32\")\n",
    "        embeddings[word.lower()]= embed\n",
    "    \n",
    "print('Found %s word vectors.' % len(embeddings))\n",
    "print(len(embeddings[word]), \" : Embedding Dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Create embedding matrix\n",
    "####\n",
    "EMBED_DIM=100\n",
    "num_words = len(vocabulary_dict) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBED_DIM))\n",
    "for word, i in vocabulary_dict.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embeddings_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(vocabulary_dict.keys())\n",
    "hidden_size = EMBED_DIM #Has to be same as EMBED_DIM\n",
    "\n",
    "#### Set maximum for CNN\n",
    "MAX_SEQUENCE_LENGTH=3196\n",
    "print(MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "kernel_sizes = [2,4,5]\n",
    "filter_size = 128\n",
    "\n",
    "X_train = liar_df_train['word_id']\n",
    "X_val = liar_df_val['word_id']\n",
    "X_test = liar_df_test['word_id']\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "Y_train = liar_df_train['numer_truth']\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=2)\n",
    "\n",
    "Y_val = liar_df_val['numer_truth']\n",
    "Y_val = keras.utils.to_categorical(Y_val, num_classes=2)\n",
    "\n",
    "#### Introduce padding\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post',truncating='post')\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH, padding='post',truncating='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH, padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Define CNN model\n",
    "####\n",
    "\n",
    "kernel_stmt = []\n",
    "\n",
    "\n",
    "statement_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='main_input')\n",
    "x_stmt = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH ,trainable=False)(statement_input) \n",
    "\n",
    "for kernel in kernel_sizes:\n",
    "    x_1 = Conv1D(filters=filter_size,kernel_size=kernel,activation='relu')(x_stmt)\n",
    "    x_1 = GlobalMaxPool1D()(x_1)\n",
    "    kernel_stmt.append(x_1)\n",
    "    \n",
    "\n",
    "conv_in1 = keras.layers.concatenate(kernel_stmt)\n",
    "conv_in1 = Dropout(0.5)(conv_in1)\n",
    "conv_in1 = Dense(128, activation='relu')(conv_in1)  \n",
    "\n",
    "\n",
    "main_output = Dense(2, activation='softmax', name='main_output')(conv_in1)\n",
    "\n",
    "model_cnn = Model(inputs=[statement_input], outputs=[main_output])\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Create folder to save checkpoints in\n",
    "####\n",
    "import os\n",
    "try:\n",
    "    os.mkdir('modelweights2')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Prepare model for training\n",
    "####\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 128\n",
    "\n",
    "#opt = optimizers.Adadelta(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "import math\n",
    "\n",
    "opt = optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model_cnn.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "print(\"[INFO] training...\")\n",
    "\n",
    "\n",
    "checkpoint_filepath = 'modelweights2/weights.{epoch:02d}.hdf5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath= checkpoint_filepath,save_weights_only=True,\n",
    "    monitor='val_acc', #monitor validation accuracy\n",
    "    mode='max', #mode\n",
    "    save_best_only=False) #only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train model\n",
    "\n",
    "H =  model_cnn.fit(x=X_train, \n",
    "                   y=Y_train,\n",
    "                   batch_size = BS,\n",
    "                   steps_per_epoch=math.ceil(len(X_train) / BS),\n",
    "                   validation_data = (X_val,Y_val),\n",
    "                   validation_steps=math.ceil(len(X_val) / BS),\n",
    "                   epochs=EPOCHS,\n",
    "                   callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load model with best validation accuracy\n",
    "\n",
    "model_cnn.load_weights('modelweights2/weights.10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predict test set and display classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model_cnn.predict([X_test], batch_size=BS)\n",
    "\n",
    "Y_test = liar_df_test['numer_truth']\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "print(classification_report(Y_test.argmax(axis=1), np.argmax(predictions, axis=1), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Display confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mat_CNN = confusion_matrix(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "sns.heatmap(mat_CNN.T, square=False, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=True, yticklabels=True)\n",
    "plt.xlabel('actual label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Display ROC-Curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr, tpr)\n",
    "#save_fig(\"roc_curve_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set maximum for RNN based models and repeat other steps accordingly\n",
    "MAX_SEQUENCE_LENGTH=40\n",
    "print(MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "X_train = liar_df_train['word_id']\n",
    "X_val = liar_df_val['word_id']\n",
    "X_test = liar_df_test['word_id']\n",
    "\n",
    "Y_train = liar_df_train['numer_truth']\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=2)\n",
    "\n",
    "Y_val = liar_df_val['numer_truth']\n",
    "Y_val = keras.utils.to_categorical(Y_val, num_classes=2)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post',truncating='post')\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=MAX_SEQUENCE_LENGTH, padding='post',truncating='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH, padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define LSTM model\n",
    "\n",
    "statement_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='main_input')\n",
    "x_stmt = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH ,trainable=False)(statement_input)\n",
    "x1 = LSTM(50, return_sequences=False)(x_stmt)\n",
    "main_output = Dense(2, activation='softmax', name='main_output')(x1)\n",
    "\n",
    "model_lstm = Model(inputs=[statement_input], outputs=[main_output])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Prepare model for training\n",
    "####\n",
    "EPOCHS = 30\n",
    "BS = 128\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\n",
    "model_lstm.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "print(\"[INFO] training...\")\n",
    "\n",
    "#### Overwriting checkpoints from previous model!\n",
    "checkpoint_filepath = 'modelweights2/weights.{epoch:02d}.hdf5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath= checkpoint_filepath,save_weights_only=True,\n",
    "    monitor='val_acc', #monitor validation accuracy\n",
    "    mode='max', #mode\n",
    "    save_best_only=False) #only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training model\n",
    "H =  model_lstm.fit(x=X_train, \n",
    "                   y=Y_train,\n",
    "                   batch_size = BS,\n",
    "                   steps_per_epoch=math.ceil(len(X_train) / BS),\n",
    "                   validation_data = (X_val,Y_val),\n",
    "                   validation_steps=math.ceil(len(X_val) / BS),\n",
    "                   epochs=EPOCHS,\n",
    "                   callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load best model\n",
    "model_lstm.load_weights('modelweights2/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lstm.predict([X_test], batch_size=BS)\n",
    "\n",
    "Y_test = liar_df_test['numer_truth']\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "print(classification_report(Y_test.argmax(axis=1), np.argmax(predictions, axis=1), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_lstm = confusion_matrix(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "sns.heatmap(mat_lstm.T, square=False, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=True, yticklabels=True)\n",
    "plt.xlabel('actual label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr, tpr)\n",
    "#save_fig(\"roc_curve_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#### Define Bi-directional LSTM model\n",
    "######################################\n",
    "statement_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='main_input')\n",
    "x_stmt = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH ,trainable=False)(statement_input)\n",
    "x1 = Bidirectional(LSTM(50, return_sequences=False))(x_stmt)\n",
    "main_output = Dense(2, activation='softmax', name='main_output')(x1)\n",
    "\n",
    "model_bi_lstm = Model(inputs=[statement_input], outputs=[main_output])\n",
    "model_bi_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Prepare model for training\n",
    "####\n",
    "EPOCHS = 30\n",
    "BS = 128\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\n",
    "model_bi_lstm.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "print(\"[INFO] training...\")\n",
    "\n",
    "#### Overwriting checkpoints from previous model!\n",
    "checkpoint_filepath = 'modelweights2/weights.{epoch:02d}.hdf5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath= checkpoint_filepath,save_weights_only=True,\n",
    "    monitor='val_acc', #monitor validation accuracy\n",
    "    mode='max', #mode\n",
    "    save_best_only=False) #only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training model\n",
    "H =  model_bi_lstm.fit(x=X_train, \n",
    "                   y=Y_train,\n",
    "                   batch_size = BS,\n",
    "                   steps_per_epoch=math.ceil(len(X_train) / BS),\n",
    "                   validation_data = (X_val,Y_val),\n",
    "                   validation_steps=math.ceil(len(X_val) / BS),\n",
    "                   epochs=EPOCHS,\n",
    "                   callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load best model\n",
    "model_bi_lstm.load_weights('modelweights2/best_model')\n",
    "\n",
    "predictions = model_bi_lstm.predict([X_test], batch_size=BS)\n",
    "\n",
    "Y_test = liar_df_test['numer_truth']\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "print(classification_report(Y_test.argmax(axis=1), np.argmax(predictions, axis=1), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_bi_lstm = confusion_matrix(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "sns.heatmap(mat_bi_lstm.T, square=False, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=True, yticklabels=True)\n",
    "plt.xlabel('actual label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr, tpr)\n",
    "#save_fig(\"roc_curve_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#### Define Bi-directional LSTM model\n",
    "#######################################\n",
    "statement_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='main_input')\n",
    "x_stmt = Embedding(vocab_length+1,EMBED_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH ,trainable=False)(statement_input)\n",
    "x1 = GRU(100, return_sequences=False)(x_stmt)\n",
    "main_output = Dense(2, activation='softmax', name='main_output')(x1)\n",
    "\n",
    "model_gru = Model(inputs=[statement_input], outputs=[main_output])\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Prepare model for training\n",
    "####\n",
    "EPOCHS = 30\n",
    "BS = 128\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)\n",
    "model_gru.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "print(\"[INFO] training...\")\n",
    "\n",
    "#### Overwriting checkpoints from previous model!\n",
    "checkpoint_filepath = 'modelweights2/weights.{epoch:02d}.hdf5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath= checkpoint_filepath,save_weights_only=True,\n",
    "    monitor='val_acc', #monitor validation accuracy\n",
    "    mode='max', #mode\n",
    "    save_best_only=False) #only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training model\n",
    "H =  model_gru.fit(x=X_train, \n",
    "                   y=Y_train,\n",
    "                   batch_size = BS,\n",
    "                   steps_per_epoch=math.ceil(len(X_train) / BS),\n",
    "                   validation_data = (X_val,Y_val),\n",
    "                   validation_steps=math.ceil(len(X_val) / BS),\n",
    "                   epochs=EPOCHS,\n",
    "                   callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load best model\n",
    "model_gru.load_weights('modelweights2/best_model')\n",
    "\n",
    "predictions = model_gru.predict([X_test], batch_size=BS)\n",
    "\n",
    "Y_test = liar_df_test['numer_truth']\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "print(classification_report(Y_test.argmax(axis=1), np.argmax(predictions, axis=1), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_gru = confusion_matrix(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "sns.heatmap(mat_gru.T, square=False, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=True, yticklabels=True)\n",
    "plt.xlabel('actual label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_test.argmax(axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr, tpr)\n",
    "#save_fig(\"roc_curve_plot\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
